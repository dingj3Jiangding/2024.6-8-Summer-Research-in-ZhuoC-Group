{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb10b68-bd11-4c3a-a145-65db5a1db750",
   "metadata": {},
   "source": [
    "1. load data\n",
    "2. import VGG16 discard FC layer,expand dims, preprocess the input\n",
    "3. extract characteristics\n",
    "4. Flatten\n",
    "5. visualize the data\n",
    "6. Split the training and test data\n",
    "7. Construct MLP Model (1 hidden layers 10 units, 1 output layer)\n",
    "8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49e12c25-7fbd-4f3e-8578-4a37fac5049b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12500 pics in dir C:/非系统/dogs-vs-cats/train/train/cat/\n",
      "the number of pic move to ./test/cat/: 9375\n",
      "save_test_dir already existed!\n",
      "save_train_dir already existed!\n",
      "test move success!\n",
      "train move success!\n",
      "There are 12500 pics in dir C:/非系统/dogs-vs-cats/train/train/dog/\n",
      "the number of pic move to ./test/dog/: 9375\n",
      "save_test_dir already existed!\n",
      "save_train_dir already existed!\n",
      "test move success!\n",
      "train move success!\n",
      "All data has been moved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import csv\n",
    "import numpy as np\n",
    "def CopyFile(imageDir,test_rate,save_test_dir,save_train_dir):\n",
    "    image_number = len(imageDir)\n",
    "    test_number = int(image_number * test_rate)\n",
    "    print(\"the number of pic move to %s: %d\" %(save_test_dir,test_number))\n",
    "    test_samples = random.sample(imageDir, test_number)\n",
    "    if not os.path.exists(save_test_dir):\n",
    "        os.makedirs(save_test_dir)\n",
    "        print(\"save_test_dir has been created successfully!\")\n",
    "    else:\n",
    "        print(\"save_test_dir already existed!\")\n",
    "    if not os.path.exists(save_train_dir):\n",
    "        os.makedirs(save_train_dir)\n",
    "        print(\"save_train_dir has been created successfully!\")\n",
    "    else:\n",
    "        print(\"save_train_dir already existed!\")\n",
    "    for i,j in enumerate(test_samples):\n",
    "        shutil.copy(test_samples[i],save_test_dir+test_samples[i].split(\"/\")[-1])\n",
    "    print(\"test move success!\")\n",
    "    for train_imgs in imageDir:\n",
    "        if train_imgs not in test_samples:\n",
    "            shutil.copy(train_imgs, save_train_dir+train_imgs.split('/')[-1])\n",
    "    print(\"train move success!\")\n",
    "\n",
    "\n",
    "file_path = \"C:/非系统/dogs-vs-cats/train/train\"\n",
    "test_rate = 0.75\n",
    "\n",
    "file_dirs = os.listdir(file_path)\n",
    "origin_dirs = []\n",
    "save_test_dirs = []\n",
    "save_train_dirs = []\n",
    "for path in file_dirs:\n",
    "    origin_dirs.append(file_path + \"/\" + path +\"/\")\n",
    "    save_test_dirs.append(\"./test/\"+path+\"/\")\n",
    "    save_train_dirs.append(\"./train/\"+path+\"/\")\n",
    "for i,origin_path in enumerate(origin_dirs):\n",
    "    image_list = os.listdir(origin_path)\n",
    "    image_dir = []\n",
    "    for x,y in enumerate(image_list):\n",
    "        image_dir.append(os.path.join(origin_path,y))\n",
    "    print(\"There are %d pics in dir %s\" %(len(image_dir),origin_path))\n",
    "    CopyFile(image_dir,test_rate,save_test_dirs[i],save_train_dirs[i])\n",
    "print(\"All data has been moved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce3ba636-5519-4500-bb8c-30d5885c2a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17120 images belonging to 2 classes.\n",
      "Found 24521 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#expand dims and preprocess the input\n",
    "\n",
    "# from tensorflow.keras.preprocessing.image import img_to_array, load_img is used for process single img\n",
    "# or define a picture generator yourself[configure the ways of preprocessing yourself]\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_gen = ImageDataGenerator(rescale =1./255, rotation_range =40, width_shift_range = 0.2, height_shift_range = 0.2, zoom_range = 0.2)\n",
    "train_data = data_gen.flow_from_directory(\"./train\",target_size = (224,224),batch_size = 32, class_mode = 'binary')\n",
    "test_data = data_gen.flow_from_directory(\"./test\",target_size = (224,224),batch_size = 32, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c9abe438-7726-41a9-96a6-21d3403323e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for single pic\n",
    "# from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "# from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "# import numpy as np\n",
    "# # Since we need to reconfigure the picture\n",
    "\n",
    "# def preprocessing(img_path):\n",
    "#     pic_target = img_path\n",
    "#     pic_target = load_img(pic_target,target_size =(224,224))\n",
    "#     pic_target = img_to_array(pic_target)\n",
    "#     return pic_target\n",
    "\n",
    "# img = preprocessing('./train/cat/cat.4.jpg')\n",
    "# ##preprocess the input\n",
    "# x = np.expand_dims(img,axis = 0)   # add the dim before the first dimension\n",
    "# # otherwise the result x shape will be 224,224,3\n",
    "# print(type(x))\n",
    "# print(x.shape)\n",
    "# x = preprocess_input(x)\n",
    "# print(type(x))\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "abeae7ad-4f62-45d9-bafe-fbe6c1da4dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize the data\n",
    "\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig = plt.figure(figsize = (5,5))\n",
    "# img = load_img('./train/cat/cat.4.jpg', target_size = (224,224))\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a8f02c8-9962-4238-ab21-9f7f2e0e35bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"block5_pool_8/Identity:0\", shape=(None, None, None, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# import VGG16 discard FC layer\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from tensorflow.keras.Models import Sequence\n",
    "\n",
    "model_vgg = VGG16(weights = \"imagenet\",include_top = False)\n",
    "x = model_vgg.output\n",
    "print(x)\n",
    "#如果要开发新模型，则使用none的权重参数\n",
    "#include_top 表示是否使用全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b91bb28e-858c-4b51-871a-6422396380cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  批量预处理的方法\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "modelvgg = VGG16(weights = 'imagenet',include_top = False)\n",
    "def modelPreprocess(img_path,model):\n",
    "    img = load_img(img_path,target_size=(224,224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img,axis = 0)\n",
    "    img = preprocess_input(img)\n",
    "    x = modelvgg.predict(img)\n",
    "    x = x.reshape(1,7*7*512)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e52d7c0e-65ab-415d-93bb-fda254e85063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "a = os.listdir(\"./test/dog/\")\n",
    "for i in a:\n",
    "    print(type(i))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7390c5-afbc-41db-bb05-79604bc3bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dirs= [\"./test\",\"./train\"]\n",
    "sub_dirs = [\"cat\",\"dog\"]\n",
    "\n",
    "feastures = []\n",
    "for i,dir in enumerate(dirs):\n",
    "    sub_features = []\n",
    "    for j,sub_dir in enumerate(sub_dirs):\n",
    "        curr_path = os.path.join(dir,sub_dir)\n",
    "        pics = os.listdir(curr_path)\n",
    "        feature = np.zeros([len(pics),7*7*512])\n",
    "        for x in range(len(pics)):\n",
    "            feature = modelPreprocess(curr_path+\"/\"+pics[x],modelvgg)\n",
    "            print(\"Preprocessed: \", pics[x])\n",
    "            sub_features.append(feature)\n",
    "    features.append(sub_features)\n",
    "\n",
    "print(features[0].shape,features[1].shape)\n",
    "y1 = np.ones(12500)\n",
    "y1 = np.zeros(12500)\n",
    "x = np.concatenate((features[0][0],features[1][0],features[0][1],features[1][1]),axis = 0)\n",
    "y = np.concatenate(y1,y2)\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb15b8-7f79-4121-a907-e235b263d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train and test dataset\n",
    "from sklearn.model.selection import train_test_split \n",
    "(x_train, x_test), (y_train,y_test) = train_test_split(x,y,test_size = 0.3,random_state = 50)\n",
    "print(x_train.shape,x_test.shape,x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7fb343f0-c610-4b23-a406-4f01dcad0af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                250890    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 250,901\n",
      "Trainable params: 250,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 10, activation = 'relu', input_dim = 7*7*512))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "94407c34-a6cd-4b19-9c8b-4b209c54879c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mx_train\u001b[49m,y_train,epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss = 'binary_crossentropy',metrics = 'accuracy')\n",
    "model.fit(x_train,y_train,epochs = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
